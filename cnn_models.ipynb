{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmantation for cars driving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and building data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images do not have the same shape so we will crop it to the minimum for all dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blidi/OneDrive/Bureau/projet/semantic_segmentation/data_semantics/training/image_2')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = Path(\"%pwd\").resolve().parent\n",
    "path_data = dir / \"data_semantics/training/image_2/\"\n",
    "path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([ 370, 1224,    3]),\n",
       "indices=tensor([155, 155,   0]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vecteur pour stocker les tailles minimales des images\n",
    "min_image_sizes = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_data):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(os.path.join(path_data, filename))\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Ajoutez la taille de l'image au vecteur des tailles minimales\n",
    "            min_image_sizes.append(img.shape)\n",
    "\n",
    "# Convertissez le vecteur des tailles minimales en un tenseur PyTorch\n",
    "min_image_sizes = tch.tensor(min_image_sizes).min(0).values # don't need the indices\n",
    "min_image_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blidi/OneDrive/Bureau/projet/semantic_segmentation/data_semantics/training/semantic_rgb')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = Path(\"%pwd\").resolve().parent\n",
    "path_mask = dir / \"data_semantics/training/semantic_rgb\"\n",
    "path_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([ 370, 1224,    3]),\n",
       "indices=tensor([155, 155,   0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vecteur pour stocker les tailles minimales des images\n",
    "min_mask_sizes = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_mask):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_mask, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(os.path.join(path_mask, filename))\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Ajoutez la taille de l'image au vecteur des tailles minimales\n",
    "            min_mask_sizes.append(img.shape)\n",
    "\n",
    "# Convertissez le vecteur des tailles minimales en un tenseur PyTorch\n",
    "min_mask_sizes = tch.tensor(min_mask_sizes).min(0).values # don't need the indices\n",
    "min_mask_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping the images and building the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les images en tant que tenseurs\n",
    "images_tensor = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_data):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(os.path.join(path_data, filename))\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ### Add here the method to crop the images \n",
    "            # harsh one : pass every image to function (reduce_top = shape_img_H - min_H ; img=img[:,reduce_top:] ; same for the W)\n",
    "            \n",
    "            # if instructions to avoid passing the function on images that don't need to be cropped\n",
    "\n",
    "\n",
    "\n",
    "            # Convertissez l'image en tenseur Pytorch\n",
    "            img_tensor = tch.from_numpy(img)\n",
    "            img_tensor = img_tensor.float() / 255.0  # Normalisez les valeurs des pixels entre 0 et 1\n",
    "            # Ajoutez le tenseur de l'image à la liste\n",
    "            images_tensor.append(img_tensor)\n",
    "\n",
    "# Convertissez la liste de tenseurs en un seul tenseur contenant toutes les images\n",
    "images_tensor = tch.stack(images_tensor, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmantation for cars driving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blidi/OneDrive/Bureau/projet/semantic_segmentation/data_semantics/training/image_2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = Path(\"%pwd\").resolve().parent\n",
    "path_data = dir / \"data_semantics/training/image_2/\"\n",
    "path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les images en tant que tenseurs\n",
    "images_tensor = []\n",
    "\n",
    "# Vecteur pour stocker les tailles minimales des images\n",
    "min_image_sizes = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_data):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(os.path.join(path_data, filename))\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Convertissez l'image en tenseur Pytorch\n",
    "            img_tensor = tch.from_numpy(img.transpose(2, 0, 1))  # Transposez les dimensions pour obtenir le format correct (C x H x W)\n",
    "            img_tensor = img_tensor.float() / 255.0  # Normalisez les valeurs des pixels entre 0 et 1\n",
    "            # Ajoutez la taille minimale de l'image au vecteur des tailles minimales\n",
    "            min_image_sizes.append(img.shape)\n",
    "            # Ajoutez le tenseur de l'image à la liste\n",
    "            images_tensor.append(img_tensor)\n",
    "\n",
    "# Convertissez la liste de tenseurs en un seul tenseur contenant toutes les images\n",
    "taille =  []\n",
    "for i in images_tensor :\n",
    "    taille.append(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([ 370, 1224,    3]),\n",
       "indices=tensor([155, 155,   0]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertissez le vecteur des tailles minimales en un tenseur PyTorch\n",
    "min_image_sizes_tensor = tch.tensor(min_image_sizes)\n",
    "min_image_sizes_tensor.min(0)\n",
    "#taille_uniforme = tch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blidi/OneDrive/Bureau/projet/semantic_segmentation/data_semantics/testing/image_2')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = Path(\"%pwd\").resolve().parent\n",
    "path_data = dir / \"data_semantics/testing/image_2\"\n",
    "path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les images en tant que tenseurs\n",
    "images_tensor = []\n",
    "\n",
    "# Vecteur pour stocker les tailles minimales des images\n",
    "min_image_sizes = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_data):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(os.path.join(path_data, filename))\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Convertissez l'image en tenseur Pytorch\n",
    "            img_tensor = tch.from_numpy(img.transpose(2, 0, 1))  # Transposez les dimensions pour obtenir le format correct (C x H x W)\n",
    "            img_tensor = img_tensor.float() / 255.0  # Normalisez les valeurs des pixels entre 0 et 1\n",
    "            # Ajoutez la taille minimale de l'image au vecteur des tailles minimales\n",
    "            min_image_sizes.append(img.shape)\n",
    "            # Ajoutez le tenseur de l'image à la liste\n",
    "            images_tensor.append(img_tensor)\n",
    "\n",
    "# Convertissez la liste de tenseurs en un seul tenseur contenant toutes les images\n",
    "taille =  []\n",
    "for i in images_tensor :\n",
    "    taille.append(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([ 370, 1224,    3]),\n",
       "indices=tensor([166, 166,   0]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertissez le vecteur des tailles minimales en un tenseur PyTorch\n",
    "min_image_sizes_tensor = tch.tensor(min_image_sizes)\n",
    "min_image_sizes_tensor.min(0)\n",
    "#taille_uniforme = tch.tensor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

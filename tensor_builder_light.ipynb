{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building image cars driving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and building data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images do not have the same shape so we will crop it to the minimum for all dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blidi/OneDrive/Bureau/projet/semantic_segmentation/data_semantics/training/image_2')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = Path(\"%pwd\").resolve().parent\n",
    "path_data = dir / \"data_semantics/training/image_2/\"\n",
    "path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 370, 1224,    3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vecteur pour stocker les tailles minimales des images\n",
    "min_image_sizes = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_data):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(filepath)\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Ajoutez la taille de l'image au vecteur des tailles minimales\n",
    "            min_image_sizes.append(img.shape)\n",
    "\n",
    "# Convertissez le vecteur des tailles minimales en un tenseur PyTorch\n",
    "min_image_sizes = tch.tensor(min_image_sizes).min(0).values # don't need the indices\n",
    "min_image_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blidi/OneDrive/Bureau/projet/semantic_segmentation/data_semantics/training/semantic_rgb')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = Path(\"%pwd\").resolve().parent\n",
    "path_mask = dir / \"data_semantics/training/semantic_rgb\"\n",
    "path_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 370, 1224,    3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vecteur pour stocker les tailles minimales des images\n",
    "min_mask_sizes = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_mask):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_mask, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(filepath)\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Ajoutez la taille de l'image au vecteur des tailles minimales\n",
    "            min_mask_sizes.append(img.shape)\n",
    "\n",
    "# Convertissez le vecteur des tailles minimales en un tenseur PyTorch\n",
    "min_mask_sizes = tch.tensor(min_mask_sizes).min(0).values # don't need the indices\n",
    "min_mask_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping the images and building the data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The height is 370 for the images and 370 for the masks.\n",
      "The width is 1224 for the images and 1224 for the masks.\n"
     ]
    }
   ],
   "source": [
    "print('The height is', int(min_image_sizes[0]), 'for the images and', int(min_mask_sizes[0]), 'for the masks.\\n' \n",
    "      'The width is', int(min_image_sizes[1]), 'for the images and', int(min_mask_sizes[1]), 'for the masks.')\n",
    "# Create a cell to verify that the two masks are equal, if not create a policy\n",
    "h_size, w_size, _ = min_image_sizes\n",
    "h_size = h_size - 2 # Check Creating the CNN part to see why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is driving images, we will crop it from the top for the height (because generally they are no so much information for cars in the sky) and from both side for the width. \\\\\n",
    "For the width part, if the reducing value (w_img - w_size) is odd, we will minus the exceeding one from the left because cars drive on the right side so the citizens come most rapidly from the right (so we need the more data on that part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, h_size = h_size, w_size = w_size) :\n",
    "    h, w, _ = img.shape\n",
    "    reduce_h, reduce_w = h-h_size, w-w_size\n",
    "    # it might be more efficient to add if instances to see if it necessary to crop the images or not\n",
    "    return img[reduce_h:, int(np.ceil(reduce_w/2)):w-int(np.floor(reduce_w/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les images en tant que tenseurs\n",
    "images_tensor = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_data):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_data, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(filepath)\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Cropping the image\n",
    "            img = crop_img(img)\n",
    "            # Convertissez l'image en tenseur Pytorch\n",
    "            img_tensor = tch.from_numpy(img.transpose(2, 0, 1))\n",
    "            img_tensor = img_tensor.float() / 255.0  # Normalisez les valeurs des pixels entre 0 et 1\n",
    "            # Ajoutez le tenseur de l'image à la liste\n",
    "            images_tensor.append(img_tensor)\n",
    "\n",
    "# Convertissez la liste de tenseurs en un seul tenseur contenant toutes les images\n",
    "images_tensor = tch.stack(images_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les images en tant que tenseurs\n",
    "mask_tensor = []\n",
    "\n",
    "# Parcours de chaque fichier dans le répertoire\n",
    "for filename in os.listdir(path_mask):\n",
    "    # Vérifiez si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construisez le chemin complet du fichier\n",
    "        filepath = os.path.join(path_mask, filename)\n",
    "        # Utilisez la déclaration with pour ouvrir le fichier\n",
    "        with open(filepath, 'rb') as f:    \n",
    "            # Chargez l'image avec OpenCV\n",
    "            img = cv2.imread(filepath)\n",
    "            # Convertissez l'image en BGR en RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Cropping the image\n",
    "            img = crop_img(img)\n",
    "            # Convertissez l'image en tenseur Pytorch\n",
    "            img_tensor = tch.from_numpy(img.transpose(2, 0, 1))\n",
    "            img_tensor = img_tensor.float() / 255.0  # Normalisez les valeurs des pixels entre 0 et 1\n",
    "            # Ajoutez le tenseur de l'image à la liste\n",
    "            mask_tensor.append(img_tensor)\n",
    "\n",
    "# Convertissez la liste de tenseurs en un seul tenseur contenant toutes les images\n",
    "mask_tensor = tch.stack(mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200, 3, 368, 1224])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_tensor = tch.stack((images_tensor, mask_tensor)) \n",
    "training_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing a couple of images to see if everything is ok (it may be better to view it with plt...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEAVY CELL\n",
    "# ind=np.random.randint(0, 199, 4)\n",
    "# fig = go.Figure()\n",
    "# c=0\n",
    "# for i in ind : \n",
    "#     # Transpose back the images to the good dimensions\n",
    "#     fig.add_trace(go.Image(z=np.concatenate((training_tensor[0,i].permute(1, 2, 0)*255, training_tensor[1,i].permute(1, 2, 0)*255),1), y0 = c*h_size))\n",
    "#     c+=1\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets saving\n",
    "\n",
    "# tch.save(training_tensor, Path(\"%pwd\").resolve().parent / \"data\" / \"training_tensor.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

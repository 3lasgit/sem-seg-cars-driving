{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmantation for cars driving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class ImageMaskDataset(Dataset):\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data = data_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[1]  # Nombre d'exemples dans le tensor data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extraire l'image et le masque correspondant à l'index donné\n",
    "        image = self.data[0, index]  # Première dimension pour les images\n",
    "        mask = self.data[1, index]   # Deuxième dimension pour les masques\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets\n",
    "\n",
    "path_training, path_test = Path(\"%pwd\").resolve().parent / \"data\" / \"training_dataset.pt\", Path(\"%pwd\").resolve().parent / \"data\" / \"test_dataset.pt\"\n",
    "\n",
    "training_data, test_data = tch.load(path_training), tch.load(path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model will be a custom U-Net, the batch will be one image at a time and we will not work on patches as it is said in their article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "# Création du DataLoader\n",
    "batch_size = 1\n",
    "data_loader = tch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Affichage de la taille du DataLoader, number of batch in our dataloader\n",
    "print(len(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is a custom U-Net Model. We decided to suppress the last couple of layer composed of a maxpool, a double-down convolution, an upsampling, a stacking, a double-up convolution layers. We adapted a bit the hyperparameters when needed in order to make everything work back together. \n",
    "\n",
    "We hope that it accelerates the computing without loosing too much accuracy. We may increase the number of channels through the model as we saved some layers. We will see that in the fine-tuning part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module): # Creating a class merging the double conv\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),          # X_out=X_in cf formula applied with these parameters' values\n",
    "            nn.BatchNorm2d(out_channels),                                                # keeps size\n",
    "            nn.ReLU(inplace=True),                                                       # keeps size \n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1),         \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )                                                                                # Keeps the same image size of the input\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = DoubleConv(in_channels, 64)        # keeps image size \n",
    "        self.dconv_down2 = DoubleConv(64, 128)                # keeps image size \n",
    "        self.dconv_down3 = DoubleConv(128, 256)               # keeps image size \n",
    "        self.dconv_down4 = DoubleConv(256, 512)               # keeps image size \n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2)          # X_out=int((X_in/2) + 1)   # Caution : default stride is equal to kernel-size here\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)  # X_out=int(X_in*2)       # Fasten the process as it hasn't to learn weights unlike the convtranspose (which is so )\n",
    "        \n",
    "        self.dconv_up3 = DoubleConv(256 + 512, 256)          # keeps image size \n",
    "        self.dconv_up2 = DoubleConv(128 + 256, 128)          # keeps image size\n",
    "        self.dconv_up1 = DoubleConv(128 + 64, 64)            # keeps image size\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, out_channels, 1)      # keeps image size\n",
    "\n",
    "    def forward(self, x): \n",
    "        conv1 = self.dconv_down1(x)          \n",
    "        x = self.maxpool(conv1)     \n",
    "\n",
    "        conv2 = self.dconv_down2(x)          \n",
    "        x = self.maxpool(conv2)     \n",
    "\n",
    "        conv3 = self.dconv_down3(x)          \n",
    "        x = self.maxpool(conv3)     \n",
    "\n",
    "        x = self.dconv_down4(x)    \n",
    "        x = self.upsample(x)        \n",
    "        # print('La taille de x est ', x.shape, 'et la taille de conv3 est ', conv3.shape)\n",
    "        x = tch.cat([x, conv3], dim=1) \n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)\n",
    "        # print('La taille de x est ', x.shape, 'et la taille de conv2 est ', conv2.shape)\n",
    "        x = tch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)\n",
    "        #  print('La taille de x est ', x.shape, 'et la taille de conv1 est ', conv3.shape)\n",
    "        x = tch.cat([x, conv1], dim=1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "        out = self.conv_last(x)\n",
    "        return out\n",
    "    \n",
    "\n",
    "unet_model = UNet(in_channels = 3, out_channels = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had a problem in the concatening steps, the size doesn't match. After investigating the problem, we found that at a step the height size became odd and so the division by 2 let us loss a range of pixel on the height and after that it creates an offset with the mutltiplication so instead of cropping twice inside the model at each stacjking steep with an issue, we found it better to crop 2 range of pixels from each image on the height side in the dataset's generation, hence the height will be more divisible by 2 (more 2 in the prime factors decomposition).\n",
    "\n",
    "Also in that case, we could change our custom Unet model back to the usual one if needed without changing more the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Définir la fonction de perte (criterion) et l'optimiseur\u001b[39;00m\n\u001b[0;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43munet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m unet_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m n_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:278\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    275\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:45\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     34\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     transform_code_object,\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_size\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     CacheSizeRelevantForFrame,\n\u001b[0;32m     41\u001b[0m     compute_cache_size,\n\u001b[0;32m     42\u001b[0m     exceeds_cache_size_limit,\n\u001b[0;32m     43\u001b[0m     is_recompilation,\n\u001b[0;32m     44\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m always_optimize_code_objects, skip_code, TorchPatcher\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     augment_exc_message,\n\u001b[0;32m     48\u001b[0m     BackendCompilerFailed,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     Unsupported,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CheckFunctionManager,\n\u001b[0;32m     58\u001b[0m     get_and_maybe_log_recompilation_reason,\n\u001b[0;32m     59\u001b[0m     GuardedCode,\n\u001b[0;32m     60\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:69\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39meval_frame, name)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, external_utils, skipfiles, utils\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CondOpArgsMismatchError, UserError, UserErrorType\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_dynamo\\skipfiles.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_store\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     41\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     42\u001b[0m     UserMethodVariable,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mA note on skipfiles:\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03myou don't want to inline them.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m BUILTIN_SKIPLIST \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m     abc,\n\u001b[0;32m     92\u001b[0m     collections,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     _weakrefset,\n\u001b[0;32m    122\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:26\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdicts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     ConstDictVariable,\n\u001b[0;32m     16\u001b[0m     CustomizedDictVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     SetVariable,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     23\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     24\u001b[0m     UserMethodVariable,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchHigherOrderOperatorVariable\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     CountIteratorVariable,\n\u001b[0;32m     29\u001b[0m     CycleIteratorVariable,\n\u001b[0;32m     30\u001b[0m     IteratorVariable,\n\u001b[0;32m     31\u001b[0m     RepeatIteratorVariable,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyVariableTracker\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\higher_order_ops.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_python_dispatcher\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy_to_fake_tensor, get_fake_value, get_real_value\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\onnx\\__init__.py:10\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _onnx \u001b[38;5;28;01mas\u001b[39;00m _C_onnx\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     _CAFFE2_ATEN_FALLBACK,\n\u001b[0;32m      5\u001b[0m     OperatorExportTypes,\n\u001b[0;32m      6\u001b[0m     TensorProtoDataType,\n\u001b[0;32m      7\u001b[0m     TrainingMode,\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort:skip. Keep the order instead of sorting lexicographically\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     _deprecation,\n\u001b[0;32m     12\u001b[0m     errors,\n\u001b[0;32m     13\u001b[0m     symbolic_caffe2,\n\u001b[0;32m     14\u001b[0m     symbolic_helper,\n\u001b[0;32m     15\u001b[0m     symbolic_opset7,\n\u001b[0;32m     16\u001b[0m     symbolic_opset8,\n\u001b[0;32m     17\u001b[0m     symbolic_opset9,\n\u001b[0;32m     18\u001b[0m     symbolic_opset10,\n\u001b[0;32m     19\u001b[0m     symbolic_opset11,\n\u001b[0;32m     20\u001b[0m     symbolic_opset12,\n\u001b[0;32m     21\u001b[0m     symbolic_opset13,\n\u001b[0;32m     22\u001b[0m     symbolic_opset14,\n\u001b[0;32m     23\u001b[0m     symbolic_opset15,\n\u001b[0;32m     24\u001b[0m     symbolic_opset16,\n\u001b[0;32m     25\u001b[0m     symbolic_opset17,\n\u001b[0;32m     26\u001b[0m     symbolic_opset18,\n\u001b[0;32m     27\u001b[0m     utils,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# TODO(After 1.13 release): Remove the deprecated SymbolicContext\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exporter_states\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportTypes, SymbolicContext\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\onnx\\symbolic_opset11.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _onnx \u001b[38;5;28;01mas\u001b[39;00m _C_onnx\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     _type_utils,\n\u001b[0;32m     14\u001b[0m     errors,\n\u001b[0;32m     15\u001b[0m     symbolic_helper,\n\u001b[0;32m     16\u001b[0m     symbolic_opset10 \u001b[38;5;28;01mas\u001b[39;00m opset10,\n\u001b[0;32m     17\u001b[0m     symbolic_opset9 \u001b[38;5;28;01mas\u001b[39;00m opset9,\n\u001b[0;32m     18\u001b[0m     utils,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_globals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLOBALS\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _beartype, jit_utils, registration\n",
      "File \u001b[1;32mc:\\Users\\blidi\\OneDrive\\Bureau\\projet\\semantic_segmentation\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:45\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     _constants,\n\u001b[0;32m     39\u001b[0m     _exporter_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     symbolic_helper,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_globals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLOBALS\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     46\u001b[0m     _beartype,\n\u001b[0;32m     47\u001b[0m     diagnostics,\n\u001b[0;32m     48\u001b[0m     jit_utils,\n\u001b[0;32m     49\u001b[0m     onnx_proto_utils,\n\u001b[0;32m     50\u001b[0m     registration,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_in_onnx_export\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect_model_mode_for_export\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munregister_custom_op_symbolic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m ]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_in_onnx_export\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Définir la fonction de perte (criterion) et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = tch.optim.Adam(unet_model.parameters(), lr=0.001)\n",
    "\n",
    "unet_model.train()\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch) :\n",
    "    running_loss = 0.0\n",
    "    for image, mask in data_loader :\n",
    "        # Remettre à zéro les gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = unet_model(image)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(pred, mask)\n",
    "\n",
    "        # Backpropagation and update of the weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate the whole loss of the epoch\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Afficher la perte moyenne de l'époque\n",
    "    print(f\"Epoch [{epoch+1}/{n_epoch}], Loss: {running_loss/len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = Path(\"%pwd\").resolve().parent / 'unet_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saving\n",
    "# tch.save(unet_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Loading\n",
    "# unet_model = UNet(in_channels = 3, out_channels = 3)\n",
    "# unet_model.load_state_dict(tch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43munet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble de test\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with tch.no_grad():\n",
    "    for i in len(test_data) :\n",
    "        image, mask = test_data[0,i], test_data[1,i]\n",
    "        outputs = unet_model(image)\n",
    "        _, predicted = tch.max(outputs, 1)\n",
    "        total_correct += (predicted == mask).sum().item()\n",
    "        total_samples += mask.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculer la précision\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtotal_correct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_samples\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy on test set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Calculer la précision\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
